{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import base64\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "from copy import deepcopy\n",
    "# from evaluation.utils import code_to_image\n",
    "import matplotlib.pyplot as plt\n",
    "from loguru import logger # type: ignore\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential, stop_after_delay,\n",
    ")\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "QUERY_EXPANSION_PROMPT='''According to the user query, expand and solidify the query into a step by step detailed instruction (or comment) on how to write python code to fulfill the user query's requirements. Import the appropriate libraries. Pinpoint the correct library functions to call and set each parameter in every function call accordingly.'''\n",
    "\n",
    "SYSTEM_PROMPT_CODE_GEN='''You are a helpful assistant that generates Python code for data visualization and analysis using matplotlib, seaborn and pandas. Given a detailed instruction and data description, generate the appropriate code in the Markdwon format of ```python ...```. MUST FOLLOW THE FORMAT.'''\n",
    "\n",
    "FEEDBACK_SYSTEM_PROMPT = '''Given a piece of code, a user query, and an image of the current plot, please determine whether the plot has faithfully followed the user query. Your task is to provide instruction to make sure the plot has strictly completed the requirements of the query. Please output a detailed step by step instruction on how to use python code to enhance the plot.'''\n",
    "\n",
    "FEEDBACK_USER_PROMPT = '''Here is the code: [Code]:\n",
    "\"\"\"\n",
    "{{code}}\n",
    "\"\"\"\n",
    "\n",
    "Here is the user query: [Query]:\n",
    "\"\"\"\n",
    "{{query}}\n",
    "\"\"\"\n",
    "\n",
    "Carefully read and analyze the user query to understand the specific requirements. Examine the provided Python code to understand how the current plot is generated. Check if the code aligns with the user query in terms of data selection, plot type, and any specific customization. Look at the provided image of the plot. Assess the plot type, the data it represents, labels, titles, colors, and any other visual elements. Compare these elements with the requirements specified in the user query. Note any differences between the user query requirements and the current plot. Based on the identified discrepancies, provide step-by-step instructions on how to modify the Python code to meet the user query requirements. Suggest improvements for better visualization practices, such as clarity, readability, and aesthetics, while ensuring the primary focus is on meeting the user's specified requirements. If there is no base64 image due to an error(EX. \"Error during Saving plot image: [Errno 2] No such file or directory: 'your_data.csv\"), please check the error message and provide feedback based on the specific issue. The feedback should suggest appropriate actions to resolve the issue according to the error details.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 6\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_gpt4o_tokens(text: str) -> int:\n",
    "    \"\"\"\n",
    "    GPT-4o 모델의 입력 텍스트에 대한 토큰 개수를 계산하는 함수\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")  # GPT-4o에서 사용하는 인코딩\n",
    "    tokens = encoding.encode(text)\n",
    "    print(f\"Token count: {len(tokens)}\")\n",
    "    # return len(tokens)\n",
    "\n",
    "# 테스트 예제\n",
    "sample_text = \"Hello, how are you?\"\n",
    "token_count = count_gpt4o_tokens(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"API_KEY\")\n",
    "base_url = os.getenv(\"BASE_URL\")\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "model = 'gpt-4o-mini'\n",
    "temperature = 0.2\n",
    "# sample = [10, 20, 30, 40, 50]\n",
    "sample = 50\n",
    "dataset_path = r\"..\\..\\dataset\\matplotbench_data.csv\"\n",
    "\n",
    "dataset_df = pd.read_csv(dataset_path)\n",
    "query_list = dataset_df.loc[sample,'simple_instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_save_path = f'./{sample}.png'\n",
    "data_description='''There is no dataset provided.'''\n",
    "QUERY_EXPANSION_PROMPT='''According to the user query, expand and solidify the query into a step by step detailed instruction (or comment) on how to write python code to fulfill the user query's requirements. Import the appropriate libraries. Pinpoint the correct library functions to call and set each parameter in every function call accordingly.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=0.02, max=1), stop=(stop_after_delay(3) | stop_after_attempt(30)))\n",
    "async def _call_openai_api(system_prompt, user_content):\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"API call failed with error: {e}. Retrying...\")\n",
    "        raise e\n",
    "    \n",
    "async def _query_extension(nl_query):\n",
    "    return await _call_openai_api(QUERY_EXPANSION_PROMPT, nl_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 246\n"
     ]
    }
   ],
   "source": [
    "## Expansion\n",
    "count_gpt4o_tokens(query_list)\n",
    "output_extension = await _query_extension(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 997\n"
     ]
    }
   ],
   "source": [
    "# print(output_extension)\n",
    "count_gpt4o_tokens(output_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 1117\n"
     ]
    }
   ],
   "source": [
    "user_content = f\"\"\"Detailed Instructions:\n",
    "{output_extension}\n",
    "\n",
    "Data Description:\n",
    "Note that you must use the right csv data which is stated in \"data_path\". DO NOT MOCK DATA if data_path is provided!!!\n",
    "If there are no data_path then just follow the Detailed Instructions. There might be an instruction about the data.\n",
    "{data_description}\n",
    "\n",
    "Please generate Python code using `matplotlib.pyplot` and 'seaborn' and 'pandas' to create the requested plot. Ensure the code is outputted within the Markdown format like ```python\\n...```. \n",
    "You MUST follow the format and Don't savefig or save anything else.\n",
    "\"\"\"\n",
    "count_gpt4o_tokens(user_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./50.png'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx(path):\n",
    "    parts = path.rsplit('.', 1)  \n",
    "    if len(parts) == 2:\n",
    "        return \".\".join([f\"{parts[0]}_before_feedback\", parts[1]]) \n",
    "    return path  \n",
    "\n",
    "def code_to_image2(code, img_save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    exec_globals = {\"plt\": plt, \"io\": io, \"np\":np, 'sns':sns}\n",
    "    exec_locals = {}\n",
    "    print('Start Executing Code and Save Final Image')\n",
    "    try:\n",
    "        code_n = code.replace(\"plt.show()\", f\"plt.savefig('{img_save_path}')\\nplt.close('all')\")\n",
    "        exec(code_n, exec_globals, exec_locals)\n",
    "        message = \"Save Image Successfully!\"\n",
    "        print(message)\n",
    "        return code, True, None\n",
    "    except Exception as e:\n",
    "        message = f\"Error during Save : {str(e)}\"\n",
    "        print(message)\n",
    "        return code, False, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Code with Max 3 trials\n",
      "Token count: 633\n",
      "./50_before_feedback.png\n",
      "Start Executing Code and Save Final Image\n",
      "Error during Save : name 'np' is not defined\n",
      "Try Again 1\n",
      "Getting Code with Max 3 trials\n",
      "Token count: 633\n",
      "./50_before_feedback.png\n",
      "Start Executing Code and Save Final Image\n",
      "Error during Save : name 'np' is not defined\n",
      "Try Again 2\n",
      "Getting Code with Max 3 trials\n",
      "Token count: 633\n",
      "./50_before_feedback.png\n",
      "Start Executing Code and Save Final Image\n",
      "Error during Save : name 'np' is not defined\n",
      "Try Again 3\n",
      "No code unitl Max3\n"
     ]
    }
   ],
   "source": [
    "try_count = 0\n",
    "while try_count < 3:\n",
    "    print('Getting Code with Max 3 trials')\n",
    "    response_text = await _call_openai_api(SYSTEM_PROMPT_CODE_GEN, user_content)\n",
    "    # print(response_text)\n",
    "    count_gpt4o_tokens(response_text)\n",
    "    match = re.search(r'```python\\n(.*?)```', response_text, flags=re.DOTALL)\n",
    "    # print(match)\n",
    "    if match:\n",
    "        code = match.group(1).strip()\n",
    "        # print(code)\n",
    "        tmp_img_path = add_idx(img_save_path)\n",
    "        print(tmp_img_path)\n",
    "        code, log, error_message = code_to_image2(code, tmp_img_path)\n",
    "        # print(log)\n",
    "        if log:\n",
    "            # print(code)\n",
    "            print('Stop Before Max3')\n",
    "            # return code, tmp_img_path, None, data_description\n",
    "            break\n",
    "        else:\n",
    "            print(f'Try Again {try_count+1}')\n",
    "            try_count += 1\n",
    "    else:\n",
    "        print(f'Try Again {try_count+1}')\n",
    "        try_count += 1\n",
    "print('No code unitl Max3')\n",
    "# return code, None, error_message, data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _describe_data(data_path):\n",
    "    if not data_path:\n",
    "        return \"No data file provided.\"\n",
    "    try:\n",
    "        data = pd.read_csv(data_path)\n",
    "        description = {\n",
    "            \"data_path\": data_path,\n",
    "            \"columns\": list(data.columns),\n",
    "            \"dtypes\": data.dtypes.apply(lambda x: x.name).to_dict(),\n",
    "            \"shape\": data.shape,\n",
    "            \"sample\": data.head(3).to_dict()\n",
    "        }\n",
    "        return str(description)\n",
    "    except Exception as e:\n",
    "        return f\"Error reading data file: {e}\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx(path):\n",
    "    parts = path.rsplit('.', 1)  \n",
    "    if len(parts) == 2:\n",
    "        return \".\".join([f\"{parts[0]}_before_feedback\", parts[1]]) \n",
    "    return path  \n",
    "\n",
    "def code_to_image2(code, img_save_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    exec_globals = {\"plt\": plt, \"io\": io}\n",
    "    exec_locals = {}\n",
    "    print('Start Executing Code and Save Final Image')\n",
    "    try:\n",
    "        code_n = code.replace(\"plt.show()\", f\"plt.savefig('{img_save_path}')\\nplt.close('all')\")\n",
    "        exec(code_n, exec_globals, exec_locals)\n",
    "        message = \"Save Image Successfully!\"\n",
    "        print(message)\n",
    "        return code, True, None\n",
    "    except Exception as e:\n",
    "        message = f\"Error during Save : {str(e)}\"\n",
    "        print(message)\n",
    "        return code, False, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_code_content(nl_query, data_path_list, img_save_path):\n",
    "        \n",
    "    if data_path_list:\n",
    "        data_description_list = []\n",
    "        for data_path in data_path_list:\n",
    "            root_path = os.path.abspath(os.path.dirname(os.curdir))\n",
    "            data_path = os.path.normpath(os.path.join(root_path, data_path))\n",
    "            single_data_description = _describe_data(data_path)\n",
    "            data_description_list.append(single_data_description)\n",
    "        data_description = \"[\" + \"], [\".join(data_description_list) + \"]\"\n",
    "\n",
    "    else :\n",
    "        data_description='''There is no dataset provided.'''\n",
    "\n",
    "\n",
    "    extended_query = await _query_extension(nl_query)\n",
    "    \n",
    "    user_content = f\"\"\"Detailed Instructions:\n",
    "{extended_query}\n",
    "\n",
    "Data Description:\n",
    "Note that you must use the right csv data which is stated in \"data_path\". DO NOT MOCK DATA if data_path is provided!!!\n",
    "If there are no data_path then just follow the Detailed Instructions. There might be an instruction about the data.\n",
    "{data_description}\n",
    "\n",
    "Please generate Python code using `matplotlib.pyplot` and 'seaborn' and 'pandas' to create the requested plot. Ensure the code is outputted within the Markdown format like ```python\\n...```. \n",
    "You MUST follow the format and Don't savefig or save anything else.\n",
    "\"\"\"\n",
    "    \n",
    "    try_count = 0\n",
    "    while try_count < 3:\n",
    "        print('Getting Code with Max 3 trials')\n",
    "        response_text = await _call_openai_api(SYSTEM_PROMPT_CODE_GEN, user_content)\n",
    "        # print(response_text)\n",
    "        match = re.search(r'```python\\n(.*?)```', response_text, flags=re.DOTALL)\n",
    "        # print(match)\n",
    "        if match:\n",
    "            code = match.group(1).strip()\n",
    "            # print(code)\n",
    "            tmp_img_path = add_idx(img_save_path)\n",
    "            code, log, error_message = code_to_image2(code, tmp_img_path)\n",
    "            # print(log)\n",
    "            if log:\n",
    "                # print(code)\n",
    "                print('Stop Before Max3')\n",
    "                return code, tmp_img_path, None, data_description\n",
    "            else:\n",
    "                print(f'Try Again {try_count+1}')\n",
    "                try_count += 1\n",
    "        else:\n",
    "            print(f'Try Again {try_count+1}')\n",
    "            try_count += 1\n",
    "    print('No code unitl Max3')\n",
    "    return code, None, error_message, data_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image to base64 format\n",
    "def encode_image(image_path):\n",
    "    print('Encoding Image to Base64')\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def visual_feedback(ori_query, code, img_save_path, data_description):\n",
    "    # logger.info('Starting Feedback...')\n",
    "    # Encode the image to base64 for sending as a message\n",
    "    try:\n",
    "        base64_image = encode_image(img_save_path)\n",
    "    except:\n",
    "        base64_image = \"No image found due to Error\"\n",
    "        \n",
    "    # Prepare the messages for GPT-4o, including the system prompt, user prompt with code and query, and the image\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \n",
    "        \"content\": '''Given a piece of code, a user query, and an image of the current plot, please determine whether the plot has faithfully followed the user query. Your task is to provide instruction to make sure the plot has strictly completed the requirements of the query. Please output a detailed step by step instruction on how to use python code to enhance the plot.'''},\n",
    "        {\"role\": \"user\", \n",
    "        \"content\": f'''Here is the code: [Code]:\n",
    "\"\"\"\n",
    "{code}\n",
    "\"\"\"\n",
    "\n",
    "Here is the user query and the about the data description: [Query]:\n",
    "\"\"\"\n",
    "{ori_query}\n",
    "\n",
    "{data_description}\n",
    "\"\"\"\n",
    "\n",
    "Carefully read and analyze the user query to understand the specific requirements. Examine the provided Python code to understand how the current plot is generated. Check if the code aligns with the user query in terms of data selection, plot type, and any specific customization. Look at the provided image of the plot. Assess the plot type, the data it represents, labels, titles, colors, and any other visual elements. Compare these elements with the requirements specified in the user query.\n",
    "Note any differences between the user query requirements and the current plot. Based on the identified discrepancies, provide step-by-step instructions on how to modify the Python code to meet the user query requirements. Suggest improvements for better visualization practices, such as clarity, readability, and aesthetics, while ensuring the primary focus is on meeting the user's specified requirements.'''}\n",
    "]\n",
    "    count_gpt4o_tokens(messages[0]['content'])\n",
    "    count_gpt4o_tokens(messages[-1]['content'])\n",
    "\n",
    "    messages[-1][\"content\"] += f\"\\n\\n![plot](data:image/png;base64,{base64_image})\"\n",
    "    # print(messages[0]['content'])\n",
    "    # Call the completion function to get feedback from GPT-4\n",
    "    \n",
    "    feedback = await _call_openai_api(messages[0]['content'], messages[-1]['content'])\n",
    "    # print(feedback)\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_img_path\n",
    "data_description\n",
    "user_query = query_list\n",
    "initial_code = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Image to Base64\n",
      "Token count: 69\n",
      "Token count: 1073\n"
     ]
    }
   ],
   "source": [
    "visual_feedback = await visual_feedback(user_query, initial_code, img_save_path = tmp_img_path, data_description=data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 1471\n"
     ]
    }
   ],
   "source": [
    "count_gpt4o_tokens(visual_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 2115\n"
     ]
    }
   ],
   "source": [
    "async def feedback_aggregation(code, feedback, data_description):\n",
    "    code_with_feedback = \"\"\n",
    "    code_with_feedback += f\"------\\nData Description:{data_description}\\nInitial code:\\n{code}\\nFeedback :\\n{feedback}\"\n",
    "    return code_with_feedback\n",
    "\n",
    "code_with_feedback = await feedback_aggregation(initial_code, visual_feedback, data_description)\n",
    "count_gpt4o_tokens(code_with_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 645\n"
     ]
    }
   ],
   "source": [
    "response_text = await _call_openai_api(SYSTEM_PROMPT_CODE_GEN, code_with_feedback)\n",
    "count_gpt4o_tokens(response_text)\n",
    "# print('#'*5, 'Final Code based on Feedback', '#' * 5)\n",
    "# print(response_text)\n",
    "match = re.search(r\"```python(.*?)```\", response_text, flags=re.DOTALL)\n",
    "\n",
    "# match = re.search(r\"```python(.*?)plt\\.show\\(\\)\", response_text, flags=re.DOTALL)\n",
    "if match:\n",
    "    pass\n",
    "    # final_code\n",
    "    # return match.group(1).strip(), prompt\n",
    "    # print(code)\n",
    "else:\n",
    "    pass\n",
    "    # return None, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Query Expansion': {'avg_input_tokens': 222.4, 'avg_output_tokens': 1277.0},\n",
       " 'Code Generation': {'avg_input_tokens': 1382.4, 'avg_output_tokens': 1212.6},\n",
       " 'Visual Feedback': {'avg_input_tokens': 962.4, 'avg_output_tokens': 1221.4},\n",
       " 'Final Code Generation': {'avg_input_tokens': 1707.2,\n",
       "  'avg_output_tokens': 528.2}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실험 데이터\n",
    "experiments = {\n",
    "    \"Query Expansion\": {\n",
    "        \"input_tokens\": [358, 133, 167, 208, 246],\n",
    "        \"output_tokens\": [1340, 1323, 1660, 1065, 997],\n",
    "    },\n",
    "    \"Code Generation\": {\n",
    "        \"input_tokens\": [1460, 1370, 1780, 1185, 1117],\n",
    "        \"output_tokens\": [448, 1020, 1669, 1027, 1899],\n",
    "    },\n",
    "    \"Visual Feedback\": {\n",
    "        \"input_tokens\": [1086, 740, 1013, 831, 1142],\n",
    "        \"output_tokens\": [1264, 997, 1244, 1131, 1471],\n",
    "    },\n",
    "    \"Final Code Generation\": {\n",
    "        \"input_tokens\": [1730, 1352, 1838, 1501, 2115],\n",
    "        \"output_tokens\": [461, 478, 682, 375, 645],\n",
    "    },\n",
    "}\n",
    "\n",
    "# 평균 계산 함수\n",
    "def calculate_averages(experiments):\n",
    "    averages = {}\n",
    "    for stage, data in experiments.items():\n",
    "        avg_input = sum(data[\"input_tokens\"]) / len(data[\"input_tokens\"])\n",
    "        avg_output = sum(data[\"output_tokens\"]) / len(data[\"output_tokens\"])\n",
    "        averages[stage] = {\"avg_input_tokens\": avg_input, \"avg_output_tokens\": avg_output}\n",
    "    return averages\n",
    "\n",
    "# 평균 계산 실행\n",
    "average_tokens = calculate_averages(experiments)\n",
    "average_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vispath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
