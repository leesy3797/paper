{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential, stop_after_delay,\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "system_prompt_expansion='''According to the user query, expand and solidify the query into a step by step detailed instruction (or comment) on how to write python code to fulfill the user query's requirements. Import the appropriate libraries. Pinpoint the correct library functions to call and set each parameter in every function call accordingly.'''\n",
    "\n",
    "template_expansion =\"\"\"\n",
    "            Generate three distinct extended queries based on the given original query.  \n",
    "            Each extended query should be written in a Chain of Thought (CoT) style, explicitly outlining the reasoning and step-by-step methodology to achieve the goal.  \n",
    "\n",
    "            ### **Key Requirements:**  \n",
    "            - Do NOT change the goal or instructions given in the original query.  \n",
    "            - Propose **three different methodologies** to achieve the goal while maintaining the original intent.  \n",
    "            - Each extended query must be structured in a step-by-step CoT format, explaining **why** each step is necessary.  \n",
    "            - The different methodologies should vary in terms of **data processing, visualization techniques, or computation strategies**.  \n",
    "            - Ensure that the data description is analyzed and incorporated into the query design.  \n",
    "            - If no data description is provided, then strictly follow the original query.  \n",
    "\n",
    "            ### **Variations in Approach (Examples):**  \n",
    "            - Using different **data processing techniques** (e.g., pandas, NumPy, direct iteration)  \n",
    "            - Implementing various **visualization strategies** (e.g., different libraries, different styles of plots)  \n",
    "            - Exploring alternative **computation methods** (e.g., vectorized operations, grouped aggregations, iterative filtering)  \n",
    "\n",
    "            ### **Input:**  \n",
    "            The original query is: {ori_query}  \n",
    "\n",
    "            Data description is: {data_description}  \n",
    "\n",
    "            ### **Output Format:**  \n",
    "            Return the output **ONLY** in the following Python list format:  \n",
    "            ```[query_text_1, query_text_2, query_text_3]```  \n",
    "            \"\"\"\n",
    "        \n",
    "system_prompt_codegen=\"\"\"You are an expert on data visualization code generation. You should think step by step, and write the generated code in the format of ```python...```, where ... indicates the generated code. Code Must end in plt.show() and don't save figure by plt.savefig() and don't save anything else either.\"\"\"\n",
    "        \n",
    "template_codegen=\"\"\"\\\n",
    "            Based on the user's query and data description, generate Python code using Visualization Library like `matplotlib.pyplot` or 'seaborn' to create the requested plot. Ensure the code is outputted within the format ```...```, where ... indicates the generated code. Please make sure to generate the code according to the data description below. Do not include unnecessary code for saving plot figure, saving dataframe, or other unrelated tasks when generating the code. End with plt.show() and do not include anything after that.\n",
    "            You Must use data_path provided in Data Description when loading data with pd.read_csv().\n",
    "\n",
    "            User query: {query}\n",
    "\n",
    "            Data description: {data_description}\n",
    "            \"\"\"\n",
    "\n",
    "system_prompt_aggregation=\"\"\"\n",
    "        You are an expert in analyzing, improving, and synthesizing data visualization code. \n",
    "        Your role is to evaluate multiple versions of visualization code based on user queries and data descriptions, \n",
    "        integrate feedback effectively, and generate a final version that best meets the user's requirements.\"\n",
    "\"\"\"\n",
    "\n",
    "template_aggregation=\"\"\"\\\n",
    "    Think step by step and plan before generating the final code.\n",
    "\n",
    "You will be given:\n",
    "- **User Query**: Instructions on how the user wants the data visualization (plot) to be performed.\n",
    "- **Data Description**: Details about the dataset, including file paths and summaries.\n",
    "- **Code for Aggregation with Corresponding Feedback**: Three different versions of the data visualization code, each paired with its respective feedback highlighting mismatches with the user’s requirements and areas for improvement.\n",
    "\n",
    "### **Your Task:**\n",
    "1. **Understand the User's Intent**  \n",
    "   - Analyze the **User Query** to extract key visualization requirements, constraints, and goals.\n",
    "   - Carefully review the **Data Description** to ensure the final visualization correctly utilizes the given dataset.\n",
    "\n",
    "2. **Evaluate the Provided Code Versions & Feedback**  \n",
    "   - Examine all three versions of the code.\n",
    "   - Review the feedback for each version and identify common issues, missing elements, and improvement points.\n",
    "   - Determine which parts of each version align well with the user's requirements.\n",
    "\n",
    "3. **Synthesize the Best Final Version**  \n",
    "   - Construct a final version that effectively **integrates the best aspects** of the provided codes while addressing all necessary corrections from the feedback.  \n",
    "   - Ensure the final code adheres to **high readability, clarity, and maintainability** while fully complying with the user’s original instructions.  \n",
    "   - Eliminate unnecessary complexity while maintaining functionality.\n",
    "\n",
    "4. **Output the Final Version**  \n",
    "   - Provide the optimized final version inside a properly formatted code block:\n",
    "     ```\n",
    "     ```python\n",
    "     # Final optimized code\n",
    "     ...\n",
    "     ```\n",
    "     ```\n",
    "\n",
    "### **Inputs:**\n",
    "- **User Query:** {ori_query}\n",
    "- **Data Description:** {data_description}\n",
    "- **Code for Aggregation with Corresponding Feedback:** {code_for_aggregation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 6\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_gpt4o_tokens(text: str) -> int:\n",
    "    \"\"\"\n",
    "    GPT-4o 모델의 입력 텍스트에 대한 토큰 개수를 계산하는 함수\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")  # GPT-4o에서 사용하는 인코딩\n",
    "    tokens = encoding.encode(text)\n",
    "    print(f\"Token count: {len(tokens)}\")\n",
    "    return len(tokens)\n",
    "\n",
    "# 테스트 예제\n",
    "sample_text = \"Hello, how are you?\"\n",
    "token_count = count_gpt4o_tokens(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"API_KEY\")\n",
    "base_url = os.getenv(\"BASE_URL\")\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "model = 'gpt-4o-mini'\n",
    "temperature = 0.2\n",
    "# sample = [10, 20, 30, 40, 50]\n",
    "sample = 40\n",
    "dataset_path = r\"..\\..\\dataset\\matplotbench_data.csv\"\n",
    "\n",
    "dataset_df = pd.read_csv(dataset_path)\n",
    "query_list = dataset_df.loc[sample,'simple_instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_save_path = f'./{sample}.png'\n",
    "data_description='''There is no dataset provided.'''\n",
    "# QUERY_EXPANSION_PROMPT='''According to the user query, expand and solidify the query into a step by step detailed instruction (or comment) on how to write python code to fulfill the user query's requirements. Import the appropriate libraries. Pinpoint the correct library functions to call and set each parameter in every function call accordingly.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=0.02, max=1), stop=(stop_after_delay(3) | stop_after_attempt(30)))\n",
    "async def _call_openai_api(system_prompt, user_content):\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"API call failed with error: {e}. Retrying...\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 533\n"
     ]
    }
   ],
   "source": [
    "expansion_prompt = template_expansion.format(\n",
    "    ori_query=query_list,\n",
    "    data_description=data_description\n",
    "    )\n",
    "count_gpt4o_tokens(expansion_prompt)\n",
    "response_text = await _call_openai_api(system_prompt_expansion, expansion_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_gpt4o_tokens(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r'\\[.*\\]', response_text, flags=re.DOTALL)\n",
    "if match:\n",
    "    generated_query = match.group().strip()\n",
    "    try:\n",
    "        parsed_list = ast.literal_eval(generated_query)\n",
    "        # print(parsed_list)\n",
    "        if isinstance(parsed_list, list) and parsed_list:\n",
    "            # return parsed_list\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        # print(e)\n",
    "        pass\n",
    "else:\n",
    "    print(\"No match found\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Query Extension\n",
      "Token count: 346\n",
      "Token count: 62\n",
      "Token count: 176\n",
      "2 번째 Query Extension\n",
      "Token count: 346\n",
      "Token count: 62\n",
      "Token count: 176\n",
      "3 번째 Query Extension\n",
      "Token count: 346\n",
      "Token count: 62\n",
      "Token count: 176\n",
      "최종 Input Token 1224 / Output Token 528\n"
     ]
    }
   ],
   "source": [
    "total_input = 0\n",
    "total_output = 0\n",
    "\n",
    "code_list = []\n",
    "\n",
    "for idx, p_list in enumerate(parsed_list):\n",
    "    code_prompt = template_codegen.format(\n",
    "        query=query_list,\n",
    "        data_description=data_description,\n",
    "    )\n",
    "    print(f\"{idx+1} 번째 Query Extension\")\n",
    "    input_token = count_gpt4o_tokens(code_prompt)\n",
    "    system_token = count_gpt4o_tokens(system_prompt_codegen)\n",
    "\n",
    "    response_text = await _call_openai_api(system_prompt_codegen, code_prompt)\n",
    "    output_token = count_gpt4o_tokens(response_text)\n",
    "\n",
    "    total_input += input_token\n",
    "    total_input += system_token\n",
    "    \n",
    "    total_output += output_token\n",
    "\n",
    "    match = re.search(r\"```python(.*?)```\", response_text, flags=re.DOTALL)\n",
    "    if match:\n",
    "        code_content = match.group(1).strip()\n",
    "        code_list.append(code_content)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f'최종 Input Token {total_input} / Output Token {total_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_image(code, img_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "\n",
    "    exec_globals = {\"plt\": plt, \"np\": np, \"sns\" : sns}  # Define the global context for the code execution\n",
    "    exec_locals = {}  # Local context for the code execution\n",
    "    code = code.replace(\"plt.show()\", f\"plt.savefig('{img_path}')\\nplt.close('all')\")  # Replace plt.show() with savefig to save the image\n",
    "    try:\n",
    "        exec(code, exec_globals, exec_locals)  # Execute the code\n",
    "        return True, 'No Error'  # Return True if the code executed successfully\n",
    "    except Exception as e:\n",
    "        return False, f'''There are some errors in the code you gave:\n",
    "{str(e)}\n",
    "please correct the errors.'''\n",
    "    \n",
    "# Function to encode the image to base64 format\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./40_path0.png', './40_path1.png', './40_path2.png']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_idx(path, idx):\n",
    "    parts = path.rsplit('.', 1)  \n",
    "    if len(parts) == 2:\n",
    "        return \".\".join([f\"{parts[0]}_path{idx}\", parts[1]]) \n",
    "    return path  \n",
    "\n",
    "new_img_path_list = [add_idx(img_save_path, idx) for idx, _ in enumerate(code_list)]             \n",
    "new_img_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 Code Feedback\n",
      "Token count: 152\n",
      "Token count: 556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 402\n",
      "Feedback is done\n",
      "2 번째 Code Feedback\n",
      "Token count: 152\n",
      "Token count: 556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 494\n",
      "Feedback is done\n",
      "3 번째 Code Feedback\n",
      "Token count: 152\n",
      "Token count: 556\n",
      "Token count: 465\n",
      "Feedback is done\n",
      "최종 Input Token 2124 / Output Token 1361\n"
     ]
    }
   ],
   "source": [
    "total_input = 0\n",
    "total_output = 0\n",
    "\n",
    "generated_feedback_list = []\n",
    "\n",
    "for idx, (code, img_path) in enumerate(zip(code_list, new_img_path_list)):\n",
    "    print(f\"{idx+1} 번째 Code Feedback\")\n",
    "\n",
    "    # Save the plot as an image using the provided code\n",
    "    success, error_message = code_to_image(code, img_path)\n",
    "\n",
    "    if not success:\n",
    "        base64_image = error_message  # Return an error message if image saving fails\n",
    "    else:\n",
    "        # Encode the image to base64 for sending as a message\n",
    "        base64_image = encode_image(img_path)\n",
    "    \n",
    "    # Prepare the messages for GPT-4o, including the system prompt, user prompt with code and query, and the image\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''\n",
    "                Given a piece of code, a user query, and an image of the current plot, \n",
    "                please determine whether the plot has faithfully followed the user query. \n",
    "                \n",
    "                Your task is to provide instruction to make sure the plot has strictly \n",
    "                completed the requirements of the query. Please output a detailed step by step \n",
    "                instruction on how to use python code to enhance the plot. If the plot image \n",
    "                is missing, check the error message that has occurred in the code. \n",
    "                \n",
    "                Provide clear, essential instructions to modify the code based on the analysis, \n",
    "                focusing only on the discrepancies between the plot and the user query. \n",
    "                Avoid unnecessary feedback or suggestions. Do not output the final modified code, \n",
    "                only the instructions.'''\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\" : f'''\n",
    "                Here is the code: [Code]:\n",
    "                    \"\"\"\n",
    "                    {code}\n",
    "                    \"\"\"\n",
    "\n",
    "                    Here is the user query: [Query]:\n",
    "                    \"\"\"\n",
    "                    {query_list}\n",
    "                    \"\"\"\n",
    "                Carefully analyze the provided Python code, user query, and the plot image (if available) \n",
    "                to evaluate if the generated plot meets the user query requirements. If the plot image is missing,\n",
    "                check the error message that has occurred in the code. \n",
    "                \n",
    "                Compare the plot with the user query requirements, highlight discrepancies, and provide clear, \n",
    "                essential instructions to modify the code accordingly.\n",
    "\n",
    "                Additionally, suggest improvements for better visualization, focusing on clarity, readability, \n",
    "                and alignment with the user's objectives.\n",
    "                \n",
    "                Provide step-by-step instructions for code modification based on the analysis, focusing only on necessary \n",
    "                corrections. Do not provide the final modified code, only the instructions for fixing the discrepancies.\n",
    "                '''\n",
    "        }\n",
    "    ]\n",
    "    input_token = count_gpt4o_tokens(messages[0]['content']) + count_gpt4o_tokens(messages[-1]['content'])\n",
    "    messages[-1][\"content\"] += f\"\\n\\n![plot](data:image/png;base64,{base64_image})\"\n",
    "    \n",
    "    feedback = await _call_openai_api(messages[0]['content'], messages[-1]['content'])\n",
    "    output_token = count_gpt4o_tokens(feedback)\n",
    "\n",
    "    total_input += input_token\n",
    "    total_output += output_token\n",
    "\n",
    "    generated_feedback_list.append(feedback)\n",
    "\n",
    "    print('Feedback is done')\n",
    "    \n",
    "print(f'최종 Input Token {total_input} / Output Token {total_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_with_feedback = \"\"\n",
    "for i in range(len(code_list)):\n",
    "    code_with_feedback += f\"------\\ncode{i+1}:\\n{code_list[i]}\\nfeedback{i+1}:\\n{generated_feedback_list[i]}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 2473\n",
      "Token count: 62\n",
      "Fianl_code_prompt Input Token: 2535\n"
     ]
    }
   ],
   "source": [
    "final_code_prompt = template_aggregation.format(\n",
    "    ori_query=query_list,\n",
    "    data_description=data_description,\n",
    "    code_for_aggregation=code_with_feedback\n",
    ")\n",
    "user_token = count_gpt4o_tokens(final_code_prompt)\n",
    "system_token = count_gpt4o_tokens(system_prompt_codegen)\n",
    "print(f\"Fianl_code_prompt Input Token: {user_token+system_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 449\n"
     ]
    }
   ],
   "source": [
    "response_text = await _call_openai_api(system_prompt_codegen, final_code_prompt)\n",
    "count_gpt4o_tokens(response_text)\n",
    "\n",
    "match = re.search(r\"```python(.*?)```\", response_text, flags=re.DOTALL)\n",
    "if match:\n",
    "    code = match.group(1).strip()\n",
    "    # return code, extend_query_list, generated_code_list, prompt\n",
    "else:\n",
    "    pass\n",
    "    # return None, extend_query_list, generated_code_list, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Query Expansion': {'avg_input_tokens': 547.4, 'avg_output_tokens': 775.2},\n",
       " 'Code Generation': {'avg_input_tokens': 1264.8, 'avg_output_tokens': 993.2},\n",
       " 'Visual Feedback': {'avg_input_tokens': 2630.0, 'avg_output_tokens': 1568.0},\n",
       " 'Final Code Generation': {'avg_input_tokens': 3220.8,\n",
       "  'avg_output_tokens': 664.8}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균 계산 함수\n",
    "def calculate_averages(experiments):\n",
    "    averages = {}\n",
    "    for stage, data in experiments.items():\n",
    "        avg_input = sum(data[\"input_tokens\"]) / len(data[\"input_tokens\"])\n",
    "        avg_output = sum(data[\"output_tokens\"]) / len(data[\"output_tokens\"])\n",
    "        averages[stage] = {\"avg_input_tokens\": avg_input, \"avg_output_tokens\": avg_output}\n",
    "    return averages\n",
    "\n",
    "# 새로운 실험 데이터\n",
    "new_experiments = {\n",
    "    \"Query Expansion\": {\n",
    "        \"input_tokens\": [571, 683, 458, 492, 533],\n",
    "        \"output_tokens\": [719, 1000, 662, 668, 827],\n",
    "    },\n",
    "    \"Code Generation\": {\n",
    "        \"input_tokens\": [1335, 1671, 996, 1098, 1224],\n",
    "        \"output_tokens\": [1227, 1169, 780, 1262, 528],\n",
    "    },\n",
    "    \"Visual Feedback\": {\n",
    "        \"input_tokens\": [2934, 3212, 2148, 2732, 2124],\n",
    "        \"output_tokens\": [1554, 1726, 1628, 1571, 1361],\n",
    "    },\n",
    "    \"Final Code Generation\": {\n",
    "        \"input_tokens\": [3464, 3690, 2978, 3437, 2535],\n",
    "        \"output_tokens\": [701, 657, 633, 884, 449],\n",
    "    },\n",
    "}\n",
    "\n",
    "# 평균 계산 실행\n",
    "new_average_tokens = calculate_averages(new_experiments)\n",
    "new_average_tokens\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vispath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
